## Challenges for interpretation

An equally important complement to computational methods used to solve multi-omics analysis problems rests in the biological interpretation of their solutions. While better resolving biological systems, the integrated data resulting from these approaches are often even higher dimensional than each of the input datasets. Both this high-dimensionality and bbiologicaly complexity introduce further challenges in the understanding and communication of results from complex data sets and analyses. For example, as we have seen in [scNMT-seq as a case-study for epigenetic regulation], **Elana - spell this out with more of a narrative**
@ref(sec:scProteomics),
@ref(sec:scSpatial).

We'll separate out the different challenges into different levels. **Elana - expand this to flow into the next subsections**

### Interpretation for data scientists reading the methods sections requires a good understanding of the building blocks


The first is the communication within the community of data scientists, computer scientists and computational biologists ie communicating about methods within a community of practitionners who do not have the same vocabulary or background.

Many tools are used as black boxes and users
don't know or agree on what exactly the methods are doing (MOFA and tSNE are examples).
The first step in unblinding these black boxes used as methodology shortcuts is to have a clear glossary of terms and how we are using them.
Many synonyms for multimodal data exist and some have nuances, see the table we have compiled (ref: Table1).
Understanding the relation between methods developed by different teams is essential and we often try to organize the methods first, thus it is useful to create a dichotomy of methods and their underlying properties.

A very useful tool for making methodological black boxes more transparent are simulated data.
These can follow benchmark methods such as those presented in @ref(sec:sec-benchmark) and use well defined generative processes to clarify what some complex methods do.

Visualization of the data, following the step by step transformations and optimizations of data representations also help  clarify how certain methods fit models or  compress and reduce data dimensionality.
These visualizations are often very specialized (think for instance, correspondence analyses, goodness of fit plots like qqplots or rootograms or mean-variance fitting).
These intermediary plots don't usually end up in the main text of final biological publications and serve as intermediary checks to unpack the black boxes.

### Supervised versus unsupervised {#subsec:super}

One simple delineation between methods is that some
aim to predict a clearly defined outcome at the start of the project, such as recognizing the environment of tumor cells  versus that of healthy cells @ref(sec:scProteomics).
The supervised setting  often provides easier interpretations, one can easily rank the covariates and contiguous data in terms of their predictive potential.

On the other hand when data are collected using multiple
different technologies the data integration needs to provide organizing patterns that enable interpretation.
Clustering is often used as one unsupervised method and is a good example of the use of a latent variable, in this case a factor or categorical variable which was not directly measured on the data but is often used to enable simple interpretations.

In cellular biology,  a favorite such division into clusters is that involved in the definition of cell type
[@doi:10.1016/j.cels.2017.03.006].

Sometimes people get carried away in "clustering data" and manipulate the data, in cytometry one often sees cell gating done.
The goal there is to eliminate cells in intermediary states to give clearly delineated inventories of cell types or cells in discrete states, this is a static description and will not enable researchers down the road to predict or understand transtitions between types.

Although a latent factor can be a useful first approximation,  keep in mind that development of cells and their fate is a dynamic process and it can often be beneficial to keep data that enable interpretation of the cell trajectories: in that case, locally the underlying latent variable of interest is continuous along a gradient of development.

So far, we have seen two types of latent variables: clusters and a one dimensional continuous "gradient", (pseduo-time, disease progression are two examples of such latent gradients).
However the idea of latent variables is a rich anchor for many multimodal methods and can often be useful in highlighting what the modalities have in "common" and how they differ.
The commonalities are well understood in the case of classical multivariate factor  analyses where the data are decomposed into "commonalities" and uniqueness components [@doi:10.1037/h0069792].

A schematic summary of the different stages in interpretation is provided here:


![**A** Schematic diagram of stages of interpretaion and integration of data sources (**Kris to redesign**).
**B** Standards in Geographic Information Systems enable the integration of multiple layers of data  (**Kris to redesign**).
**C** Brushing an UMAP with a covariate can illustrate the dynamics of cell changes (**Kris to reinclude own fig**).](images/Interpretation_mockup.png){#fig:interpretation width="70%"}



Multiple domains of knowledge can be combined easily if there is a common coordinate system, as in geospatial analyses.This is often a goal in multimodal or conjoint analyses, when the first step is to find a common compromise or consensus on which to project each of the individual modalities.
Conjoint analyses also known as STATIS [@doi:10/c8xttz] was a very early multimodal method designed as PCA of PCAs where the first step in the analyses was to find what the different modalities had in common and define a consensus [@doi:10.1214/193940307000000455] onto which the individual tables were projected.
This method can be seen as an extension of the class of matrix decomposition methods to data cubes.
Many extensions to matrix decompositions have been designed for multimodal data, [@doi:10.3389/fgene.2019.00627] offers an overview of the relations between many of them.


### Reasonning by analogy with geospatial problems

In both the proteomics example @ref(sec:scProteomics)
and the @ref(sec:scSpatial) examplary data, a spatial dimension is already naturally available.
As in previous studies one can leverage
extensive methods developed in spatial statistics to
quantify spatial effects [@doi:10.1371/journal.pone.0012420].
Contiguity and clustering can be tested and easily understood in the spatial context.

In these cases,  layers of information can be mapped to the natural coordinate system in the same way
a GIS system incorporates them (Figure {@fig:interpretation}B).

The spatial coordinate system analogy can be pursued
further by finding a "consensus space" that provides a common coordinate system.

There are however pitfalls in using very sophisticated dimension reduction techniques which lead to over-interpretation or misinterpretation
(size of clusters in tSNE related to sampling baselines rather than density, ...)



### Disparate sources of evidence are more compelling than more of the same.

Following [Cardinal Newman's principle](https://www.encyclopedia.com/people/philosophy-and-religion/roman-catholic-and-orthodox-churches-general-biographies/john-henry-newman)^[Supposes a thesis (e.g. the guilt of an accused man) is supported by a great deal of circumstantial evidence of different forms, but in agreement with each other; then even if each piece of evidence is in itself insufficient to produce any strong belief, the thesis is decisively strengthened by their joint effect.]
disparate sources of evidence, or in this case data from different technologies, are more compelling than many replicates of the same technology.
Thus, if different technologies allow a consensus on  underlying latent variables, this information is worth retaining.


### Explaining results to biologists through generative models and simulations (ex: Factor Analysis, Hierarchical models).

Several difficulties arise when explaining summaries and conclusions, problems encountered include non-identifiability of models
or non-sufficiency of summaries, simulations can often provide effective communication tools.

One can often generate data from different probabilistic models and show that the methods cannot differentiate between the generation processes, this is the identifiability problems that most overparametrized models lead to.
Added constraints on the parameters can often
be integrated into the analyses to make them more realistic and reduce if not eliminate the identifiability issues.


### Meaningful Interpretation by linking in databases

In the right side of Figure {@fig:interpretation}A we show how connections to layers of information from outside databases can be incorporated into the final output. Real biological understanding is often subordinated to the integration
 of this contiguous information.
Either from the metadata already available in the multiassay containers as for instance in the [MultiAssayExperiment package](https://bioconductor.org/packages/release/bioc/html/MultiAssayExperiment.html) or from exterior sources such as Gene Ontologies, Biomart [@doi:10.1038/nprot.2009.97 ], Kegg, Human Cell Atlas (HCA) or other sources often available through links provided within systems like bioconductor ().




Redundant biological knowledge is often enlightening,
as many methods suffer from identifiability issues (ie in a gradient, the direction of the direction is unknown).
By providing information on the extreme points in a map
or brushing a map with known gene expression features
one can delineate orientations and clusters.

For instance coloring by CD56 across time shows the dynamics of immune response [@doi:10.3389/fimmu.2020.00714] (Figure {@fig:interpretation}C).

### Visualization tools for interpretation and communication to biologists


An example of effective visual interpretation tools is interactive brushing of UMAP plot, see Figure {@fig:interpretation}C by Kris Sankaran.


### Missing

 - Validation  through complementary data and sequential experimental design.

 - Examples from other parts, references and commentary here missing until documents become availabe (@sec:seqFish)





### References

Cell type definition:
[@doi:10.1016/j.cels.2017.03.006]

Factor Analysis:
[@doi:10.1037/h0069792]

Statis, conjoint analysis:
[@doi:10/c8xttz]

The French way:
[@doi:10.1214/193940307000000455]

Overview and connections of methods: KS
[@doi:10.3389/fgene.2019.00627]

Kevin Murphy:
Probabilistic Machine Learning, MIT Press
[@doi:10.5555/2380985]
[@isbn:978-0262018029]
[@isbn:0262018020]


GIS: reference
https://www.usgs.gov/faqs/what-a-geographic-information-system-gis

Original: https://prd-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/styles/full_width/public/thumbnails/image/8BaseLayersofTheNationalMap.JPG

Biomart:
[@doi:10.1038/nprot.2009.97]

UMAP:
[@doi:10.1038/nbt.4314]
https://arxiv.org/abs/1802.03426v2

Spatial tumor and immune cells:
[@doi:10.1371/journal.pone.0012420]

CD56 Immune cell coloring, paper with C. Blish:
[@doi:10.3389/fimmu.2020.00714]

Footnote:
Cardinal Newman wrote  **The Grammar of Assent.** and cited in  [Bruno de Finetti, Volume 1, 1974 Theory of Probability]:

*Supposes a thesis (e.g. the guilt of an accused man) is supported by a great deal of circumstantial evidence of different forms, but in agreement with each other; then even if each piece of evidence is in itself insufficient to produce any strong belief, the thesis is decisively strengthened by their joint effect.*
